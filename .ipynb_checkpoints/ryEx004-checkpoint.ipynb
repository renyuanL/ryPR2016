{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets  import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris= load_iris()\n",
    "X, y= iris.data, iris.target\n",
    "\n",
    "C= KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## k-nearest neighbors algorithm\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "![](https://goo.gl/Br5fke)\n",
    "\n",
    "-   Example of k-NN classification. \n",
    "-   The test sample (green circle) should be classified \n",
    "-   either to the first class of blue squares \n",
    "-   or to the second class of red triangles. \n",
    "\n",
    "-   If k = 3 (solid line circle) it is assigned to the second class \n",
    "-   because there are 2 triangles and only 1 square inside the inner circle. \n",
    "\n",
    "-   If k = 5 (dashed line circle) it is assigned to the first class \n",
    "-   (3 squares vs. 2 triangles inside the outer circle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已知 data 分為 藍色四邊形(第一類) 與 紅色三角形(第二類)，\n",
    "每個data 有二維座標(x,y) 故可畫在平面上，散佈如上。\n",
    "今有未知 綠色data，其亦有 二維座標(x,y)。\n",
    "\n",
    "如何決定其所屬類別？\n",
    "1. 以未知點為中心，尋找最近之 k 點已知類別的 data，\n",
    "2. 由 它們投票，取最多數決定所屬類別。\n",
    "\n",
    "以上例而言，\n",
    "- 若 k==1， 則 判定 未知點屬於 紅色三角形\n",
    "- 若 k==3， 則 判定 未知點屬於 紅色三角形\n",
    "- 若 k==5， 則 判定 未知點屬於 藍色四邊形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C\n",
    "# n_neighbors=5 可更動，最簡單的情形是 n_neighbors == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, C  # data, label, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 設定分類器\n",
    "C= KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# 訓練\n",
    "C.fit(X, y)\n",
    "\n",
    "# 辨識\n",
    "C.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 看正確率\n",
    "C.predict(X)==y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以上，就做出一個最簡單的分類器了， pattern recognition 的核心全貌便已浮現。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般而言，我們會把 資料分為 訓練集 與 測試集，\n",
    "分別用來 訓練與測試所設計的分類器。\n",
    "\n",
    "用來測試的資料不能出現於訓練集中，\n",
    "否則便算是作弊！\n",
    "所做的分類器之辨識率就不足採信。\n",
    "\n",
    "簡單的把資料分為偶數集(序號從0開始，間格為2)、奇數集(序號從1開始，間格為2)如下：\n",
    "偶數集當訓練集，奇數集當測試集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X0= X[0::2]; X1= X[1::2]\n",
    "y0= y[0::2]; y1= y[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 訓練\n",
    "C.fit(X0, y0)\n",
    "\n",
    "# 辨識 訓練集 (inside test)\n",
    "z0= C.predict(X0)\n",
    "\n",
    "# 辨識 測試集 (outside test)\n",
    "z1= C.predict(X1)\n",
    "\n",
    "z0, z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 辨識率 inside; (幾乎) 百分百 正確 (其實也沒有保證)\n",
    "z0==y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 辨識率 outside; 有一些錯誤。 (有錯是正常，如何降低錯誤率則是整個 pattern recognition 研究的重心！)\n",
    "z1==y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般而言，如何分割 data 成 訓練集 與 測試集，也有一些常見的經驗法則， scikit learn 提供了以下的方法：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y= train_test_split(X, y, \n",
    "                                                   train_size=  0.5, \n",
    "                                                   random_state=123, \n",
    "                                                   stratify= y)\n",
    "print(\"Labels for training and testing data\")\n",
    "print(train_y)\n",
    "print(test_y)\n",
    "'''\n",
    "[1 1 1 0 0 2 1 1 1 0 1 0 2 0 0 2 0 2 1 1 0 0 2 1 2 1 0 1 1 1 2 1 2 2 0 0 2\n",
    " 2 0 0 2 2 2 2 0 2 0 2 1 1 0 2 2 0 2 1 2 1 2 1 1 0 0 1 2 0 0 2 2 1 0 1 0 0\n",
    " 1]\n",
    "[0 2 1 0 2 0 1 2 0 0 2 1 2 0 1 2 2 2 2 2 1 2 1 1 2 2 0 0 1 0 0 2 0 1 0 0 1\n",
    " 1 2 2 0 1 0 1 1 2 0 1 1 1 0 2 2 2 1 0 0 1 1 0 2 1 0 2 0 2 1 1 2 0 2 1 0 0\n",
    " 1]\n",
    "'''\n",
    "# 靠著 random_state=123 可把 randomize 的情形固定下來，寫程式過程中有一些助益！\n",
    "# 靠著 stratify= y 可讓 類別分布 均勻，有助於辨識器的辨識效能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bincount(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 訓練\n",
    "C.fit(train_X, train_y)\n",
    "\n",
    "# 辨識 訓練集 (inside test)\n",
    "train_z= C.predict(train_X)\n",
    "\n",
    "# 辨識 測試集 (outside test)\n",
    "test_z= C.predict(test_X)\n",
    "\n",
    "train_z, test_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_z==train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_z==test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算錯誤率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(train_z==train_y).count(False)/len(train_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(test_z==test_y).count(False)/len(test_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 從頭來過，改變分類器的參數。\n",
    "看看有沒有可能提升辨識效能，降低錯誤率！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 設定分類器\n",
    "C= KNeighborsClassifier(n_neighbors= 2) # n_neighbors= 1 -->2 -->3\n",
    "\n",
    "# 訓練\n",
    "C.fit(train_X, train_y)\n",
    "\n",
    "# 辨識 訓練集 (inside test)\n",
    "train_z= C.predict(train_X)\n",
    "\n",
    "# 辨識 測試集 (outside test)\n",
    "test_z= C.predict(test_X)\n",
    "\n",
    "# 計算錯誤率\n",
    "err0= list(train_z==train_y).count(False)/len(train_z)\n",
    "err1= list(test_z==test_y).count(False)/len(test_z)\n",
    "\n",
    "print('err0= {}, err1= {}'.format(err0,err1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aL= []\n",
    "for k in range(1,10):\n",
    "    # 設定分類器\n",
    "    C= KNeighborsClassifier(n_neighbors= k) # n_neighbors= 1 -->2 -->3\n",
    "\n",
    "    # 訓練\n",
    "    C.fit(train_X, train_y)\n",
    "\n",
    "    # 辨識 訓練集 (inside test)\n",
    "    train_z= C.predict(train_X)\n",
    "\n",
    "    # 辨識 測試集 (outside test)\n",
    "    test_z= C.predict(test_X)\n",
    "\n",
    "    # 計算錯誤率\n",
    "    err0= list(train_z==train_y).count(False)/len(train_z)\n",
    "    err1= list(test_z==test_y).count(False)/len(test_z)\n",
    "\n",
    "    print('k={}, err0= {}, err1= {}'.format(k, err0, err1))\n",
    "    \n",
    "    # 把實驗數據存起來，進一步做分析。\n",
    "    aL += [(k, err0, err1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作圖觀察 k 與 錯誤率 的 關係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pylab as pl\n",
    "\n",
    "# 作圖觀察 k 與 錯誤率 的 關係\n",
    "\n",
    "A= np.array(aL)\n",
    "\n",
    "pl.plot(A[:,0], A[:,1], c='r', marker='o')\n",
    "pl.plot(A[:,0], A[:,2], c='b', marker='o')\n",
    "\n",
    "pl.xlabel('k')\n",
    "pl.ylabel('err')\n",
    "pl.grid('on')\n",
    "\n",
    "#pl.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 討論\n",
    "## 上圖顯示，在 本實驗之設定下， 在 k= [1..9] 之中，k=6, k=8 使得 err1 最低。\n",
    "##  err0 (inside test) 最低 未必 導致 err1(outside test) 最低。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下跟隨教科書 ch03，\n",
    "\n",
    "瀏覽 幾個 分類器，快速走一遍。\n",
    "每個分類器的原理雖各不相同，我們可以先把他們當黑盒子看待，先做出辨識率。\n",
    "\n",
    "然後逐一在 wikipedia 上找到相關文章，把原理做一番研究。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptron \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris= datasets.load_iris()\n",
    "X= iris.data[:, [2, 3]]\n",
    "y= iris.target\n",
    "\n",
    "print('Class labels:', np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Added version check for recent scikit-learn 0.18 checks\n",
    "'''\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "Version(sklearn_version)\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_std= X_train\n",
    "X_test_std=  X_test\n",
    "\n",
    "\n",
    "# data 預先 正規化，有助於 辨識效能\n",
    "\n",
    "#'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc= StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std= sc.transform(X_train)\n",
    "X_test_std=  sc.transform(X_test)\n",
    "#'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      n_iter=40, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn= Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "ppn.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 4\n"
     ]
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.05743774e-11,   6.31620264e-02,   9.36837974e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(X_test_std[0, :].reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred= lr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred= svm.predict(X_test_std)\n",
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', random_state=0, gamma=0.2, C=1.0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred= svm.predict(X_test_std)\n",
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "tree.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred= tree.predict(X_test_std)\n",
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy',\n",
    "                                n_estimators=10, \n",
    "                                random_state=1,\n",
    "                                n_jobs=2)\n",
    "forest.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred= forest.predict(X_test_std)\n",
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4, p=2, metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred= knn.predict(X_test_std)\n",
    "acc= accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
